# from langchain_huggingface import ChatHuggingFace, HuggingFacePipeline
# from dotenv import load_dotenv

# llm=HuggingFacePipeline.from_model_id(
#     model_id="mistralai/Mixtral-8x7B-Instruct-v0.1",
#     task="text-generation",
#     pipeline_kwargs={"temperature": 0}
# )

# model=ChatHuggingFace(llm=llm)
# result=model.invoke("Suggest me names of 5 suspense thriller movies")
# print(result)

'''Was Not Working On My Local Machine But this is the code.'''